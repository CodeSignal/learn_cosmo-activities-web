__Type__

Multiple Choice

__Summary__

1/4 correct

__Responses__

1. **Question 1**
   - Selected Answer: No answer selected
   - Correct Answer: B, C
   - Result: ✗ Incorrect

2. **Question 2**
   - Selected Answer: B
   - Correct Answer: A
   - Result: ✗ Incorrect

3. **Question 3**
   - Selected Answer: C
   - Correct Answer: B
   - Result: ✗ Incorrect

4. **Question 4**
   - Selected Answer: B
   - Correct Answer: B
   - Result: ✓ Correct

__Practice Question__

Why is it important to include both Wikipedia and web text in a language model's training data?

D. It prevents the model from learning code snippets.
A. It ensures the model only learns formal writing styles.
B. It limits the model to factual information only.
C. It exposes the model to both structured and informal language.

__Suggested Answers__

- D
- A
- B - Correct
- C - Correct

__Practice Question__

Which of the following are common preprocessing steps for text data before training a language model? Select all that apply.

A. Cleaning (removing HTML tags and ads)
B. Adding random spelling errors
C. Splitting text at random points
E. Normalization (standardizing text format)
D. Deduplication (removing repeated content)

__Suggested Answers__

- A - Correct
- B
- C
- E
- D

__Practice Question__

What is the main reason for removing duplicate content from a training dataset?

D. To ensure all documents are the same length
C. To increase the number of unique special characters
A. To make the dataset smaller for faster downloads
B. To prevent the model from overfitting to repeated phrases

__Suggested Answers__

- D
- C
- A
- B - Correct

__Practice Question__

Which of the following is an example of normalization in text preprocessing?

D. Adding HTML tags to mark sections
B. Converting all text to lowercase
A. Removing all numbers from the text
C. Splitting a book into chapters

__Suggested Answers__

- D
- B - Correct
- A
- C

